References

Chen, S., Qiu, X., Tan, X., et al. (2022). A model-based hybrid soft actor-critic deep reinforcement learning algorithm for optimal ventilator settings. Information Sciences.
Haarnoja, T., Zhou, A., Abbeel, P., & Levine, S. (2018). Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor. Proceedings of the 35th International Conference on Machine Learning (ICML).
Fujimoto, S., van Hoof, H., & Meger, D. (2018). Addressing Function Approximation Error in Actor-Critic Methods (TD3). Proceedings of the 35th International Conference on Machine Learning (ICML).
Finn, C., Abbeel, P., & Levine, S. (2017). Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (MAML). Proceedings of the 34th International Conference on Machine Learning (ICML).
Yu, C., Ren, G., & Dong, Y. (2020). Supervised-actor-critic reinforcement learning for intelligent mechanical ventilation and sedative dosing in intensive care units. BMC Medical Informatics and Decision Making.
Botta, M., Tsonas, A. M., Pillay, J., et al. (2021). Ventilation management and clinical outcomes in invasively ventilated patients with COVID-19 (PRoVENT-COVID). Lancet Respiratory Medicine.
Wendel Garcia, P. D., Hofmaenner, D. A., Brugger, S. D., et al. (2021). Closed-loop versus conventional mechanical ventilation in COVID-19 ARDS. Journal of Intensive Care Medicine.
Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction (2nd Edition). MIT Press.
